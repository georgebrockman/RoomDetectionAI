{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Room Detection AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building an AI using GANs to automatically detect which room in the house a picture is of. So far I have compiled a dataset of over 27000 photos across nine classes:\n",
    "\n",
    "- Bedroom\n",
    "- Bathroom\n",
    "- Kitchen\n",
    "- Study\n",
    "- Entrance Hall\n",
    "- Utility Room\n",
    "- Dinning Room\n",
    "- Living Room\n",
    "- Conservatory\n",
    "\n",
    "I am writing the code initially in this Juptyer Notebook, before training in a Google Colab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2 # may not use\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from os import listdir\n",
    "import tensorflow as tf\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to do import data \n",
    "# split into training and validation\n",
    "# augment data\n",
    "# check weights of each class to make sure each are equal. \n",
    "# initiate transfer learning \n",
    "# build a new classification head\n",
    "# compile the model \n",
    "# run a baseline training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/georgebrockman/code/georgebrockman/Autoenhance.ai/RoomDetection/images/training_data/\"\n",
    "CATEGORIES = ['bathroom', 'bedroom', 'kitchen', 'home_study', 'entrance_hall', 'utility_room', 'conservatory', 'dining_room', 'living_room']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import glob\n",
    "image_list = []\n",
    "for filename in glob.glob(path +'*.jpg'):\n",
    "    im=Image.open(filename)\n",
    "    image_list.append(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bedroom\n",
      "conservatory\n",
      ".DS_Store\n",
      "bathroom\n",
      "dining_room\n",
      "living_room\n",
      "home_study\n",
      "entrance_hall\n",
      "kitchen\n",
      "utility_room\n"
     ]
    }
   ],
   "source": [
    "for name in os.listdir(path):\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/georgebrockman/code/georgebrockman/Autoenhance.ai/RoomDetection'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv2.imread(os.path.join(folder,filename, ))\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    return images\n",
    "folder=path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_images_from_folder(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load each subfolder seperately - convert to array and then concatonate the data into one dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file paths\n",
    "root_path = '/Users/georgebrockman/code/georgebrockman/Autoenhance.ai/RoomDetection/images/training_data/'\n",
    "\n",
    "bedroom_path = root_path + 'bedroom'\n",
    "conservatory_path = root_path + 'conservatory'\n",
    "bathroom_path = root_path + 'bathroom'\n",
    "dining_path = root_path + 'dining_room'\n",
    "living_path = root_path + 'living_room'\n",
    "study_path = root_path + 'home_study'\n",
    "entrance_path = root_path + 'entrance_hall'\n",
    "kitch_path = root_path + 'kitchen'\n",
    "util_path = root_path + 'utility_room'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27677\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# add all images to a new folder named all_images\n",
    "\n",
    "train_dir = root_path\n",
    "dest_dir = '/Users/georgebrockman/code/georgebrockman/Autoenhance.ai/RoomDetection/images/all_images'\n",
    "counter = 0\n",
    "\n",
    "for subdir, dirs, files in os.walk(train_dir):\n",
    "    #print(files)\n",
    "    for file in files:\n",
    "        full_path = os.path.join(subdir, file)\n",
    "        shutil.copy(full_path, dest_dir)\n",
    "        counter += 1\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27657\n",
      "27677\n",
      "(27657, 1)\n"
     ]
    }
   ],
   "source": [
    "# store each datapoint name as one array\n",
    "\n",
    "subdirs, dirs, files = os.walk(dest_dir).__next__()\n",
    "m = len(files)\n",
    "print(m)\n",
    "\n",
    "filenames = []\n",
    "labels = np.zeros((m, 1))\n",
    "\n",
    "images_dir = dest_dir\n",
    "filenames_counter = 0\n",
    "labels_counter = -1\n",
    "\n",
    "for subdir, dirs, files in os.walk(train_dir):\n",
    "    for file in files:\n",
    "        filenames.append(file)\n",
    "        filenames_counter += 1\n",
    "        # print(labels[filenames_counter, 0])\n",
    "        #labels[filenames_counter, 0] = labels_counter\n",
    "        \n",
    "    labels_counter += 1\n",
    "    \n",
    "    \n",
    "print(len(filenames))\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the filename array as .npy file\n",
    "np.save('filenames.npy', filenames)\n",
    "\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# One hot vector representation of labels\n",
    "y_labels_one_hot = to_categorical(labels)\n",
    "\n",
    "# saving the y_labels_one_hot array as a .npy file\n",
    "np.save('y_labels_one_hot.npy', y_labels_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [27677, 27657]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-e4998143d875>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mfilenames_shuffled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_labels_one_hot_shuffled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_labels_one_hot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# saving the shuffled file.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36mshuffle\u001b[0;34m(*arrays, **options)\u001b[0m\n\u001b[1;32m    684\u001b[0m     \"\"\"\n\u001b[1;32m    685\u001b[0m     \u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'replace'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36mresample\u001b[0;34m(*arrays, **options)\u001b[0m\n\u001b[1;32m    568\u001b[0m                                                     n_samples))\n\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstratify\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.7/envs/lewagon/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 256\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [27677, 27657]"
     ]
    }
   ],
   "source": [
    "# shuffle the dataset\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "filenames_shuffled, y_labels_one_hot_shuffled = shuffle(filenames, y_labels_one_hot)\n",
    "\n",
    "# saving the shuffled file.\n",
    "# you can load them later using np.load().\n",
    "np.save('y_labels_one_hot_shuffled.npy', y_labels_one_hot_shuffled)\n",
    "np.save('filenames_shuffled.npy', filenames_shuffled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image size, mobile net uses 244 rather than 256\n",
    "IMG_WIDTH, IMG_HEIGHT = 224, 224\n",
    "IMG_SIZE = IMG_WIDTH, IMG_HEIGHT\n",
    "\n",
    "# instantiate the MobileNet V2\n",
    "IMG_SHAPE = IMG_SIZE + (3,)\n",
    "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
    "                                             include_top=False,\n",
    "                                             weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_batch, label_batch = next(iter(train_dataset)) # the next iteration in the dataset, so the first image\n",
    "feature_batch = base_model(image_batch)\n",
    "print(feature_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze the convolutional base\n",
    "base_model.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add classification head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the features to a single 1280-element vector per image\n",
    "global_av_layer = tf.keras.layers.GlobalAveragePooling2D() # averages over a 5x5 spatial \n",
    "feature_batch_av = global_av_layer(feature_batch)\n",
    "print(feature_batch_av.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply a dense layer to convert these features into a single prediction per image\n",
    "# no activation needed as the prediction will be treated as a logit (mapping of probabilities to Real Numbers)\n",
    "\n",
    "pred_layer = tf.keras.layers.Dense(1)\n",
    "pred_batch = pred_layer(feature_batch_av)\n",
    "pred_batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augmentate the data \n",
    "\n",
    "data_aug = tf.keras.Sequential([\n",
    "    tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),\n",
    "    tf.keras.layers.experimental.preprocessing.RandomRotation(0.2)\n",
    "])\n",
    "\n",
    "# rescale the pixel values to match the expected values of the MobileNetV2 model\n",
    "\n",
    "preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain together data augmentation, rescaling, base_model and feature extractor layers useing the Keras Functional API\n",
    "\n",
    "inputs = tf.keras.Input(shape=(160,160,3)) # image size and channels\n",
    "# data augmentation layer\n",
    "x = data_aug(inputs)\n",
    "# preprocess, feed x into and reassign variable\n",
    "x = preprocess_input(x)\n",
    "# basemodel, set training =False for the BN layer\n",
    "x = base_model(x, training=False)\n",
    "# feature extraction\n",
    "x = global_av_layer(x)\n",
    "# add a dropout layer \n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "\n",
    "outputs = pred_layer(x)\n",
    "model = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_learning_rate = 0.0001\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=base_learning_rate),\n",
    "              # Only two linear outputs so use BinaryCrossentropy and logits =True\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_dataset,\n",
    "                    epochs=initial_epochs,\n",
    "                    validation_data=validation_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tune and improve the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
